{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Worrying-About-Overfitting\" data-toc-modified-id=\"Worrying-About-Overfitting-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Worrying About Overfitting</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-Train-Validation-Test\" data-toc-modified-id=\"Use-Train-Validation-Test-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Use Train-Validation-Test</a></span></li><li><span><a href=\"#Model-Complexity-Graph\" data-toc-modified-id=\"Model-Complexity-Graph-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model Complexity Graph</a></span><ul class=\"toc-item\"><li><span><a href=\"#Early-Stopping\" data-toc-modified-id=\"Early-Stopping-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Early Stopping</a></span></li></ul></li></ul></li><li><span><a href=\"#When-a-Good-Model-Goes-Bad\" data-toc-modified-id=\"When-a-Good-Model-Goes-Bad-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>When a Good Model Goes Bad</a></span><ul class=\"toc-item\"><li><span><a href=\"#L1-Regularization---Absolute-Value\" data-toc-modified-id=\"L1-Regularization---Absolute-Value-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>L1 Regularization - Absolute Value</a></span></li><li><span><a href=\"#L2-Regularization---Squared-Value\" data-toc-modified-id=\"L2-Regularization---Squared-Value-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>L2 Regularization - Squared Value</a></span></li></ul></li><li><span><a href=\"#Dropout\" data-toc-modified-id=\"Dropout-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dropout</a></span><ul class=\"toc-item\"><li><span><a href=\"#Avoiding-the-Self-Perpetuating-Strength-Training\" data-toc-modified-id=\"Avoiding-the-Self-Perpetuating-Strength-Training-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Avoiding the Self-Perpetuating Strength Training</a></span></li><li><span><a href=\"#Example-Code\" data-toc-modified-id=\"Example-Code-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Example Code</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Worrying About Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A big issue is making sure we don't overfit our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Use Train-Validation-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Think of **training** as what you study for a test\n",
    "- Think of **validation** is using a practice test\n",
    "- Think of **testing** as what you use to judge the model \n",
    "\n",
    "> ***holdout*** is when your test dataset is never used for training (unlike in cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model Complexity Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Underfitting\n",
    "    + low complexity --> high bias, low variance\n",
    "    + training error: large\n",
    "    + testing error: large\n",
    "- Overfitting\n",
    "    + high complexity --> low bias, high variance\n",
    "    + training error: low\n",
    "    + testing error: large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T05:49:00.781352Z",
     "start_time": "2019-06-19T05:49:00.631957Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_error = np.array([5,3.5,2,3,4])\n",
    "train_error = np.array([4.5,3,1.5,1,0.5])\n",
    "n_epochs = np.array([5,50,100,200,300])\n",
    "\n",
    "plt.scatter(n_epochs, train_error,)\n",
    "plt.scatter(n_epochs, test_error)\n",
    "plt.legend(['train error','test error'])\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T05:50:28.763292Z",
     "start_time": "2019-06-19T05:50:28.759437Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Early Stopping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T05:50:28.763292Z",
     "start_time": "2019-06-19T05:50:28.759437Z"
    },
    "hidden": true
   },
   "source": [
    "We can stop our training early when our test error stopped dropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# When a Good Model Goes Bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When a model has large weights, the model is \"too confident\"\n",
    "\n",
    "We need to punish large (confident) weights by contributing them to the error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## L1 Regularization - Absolute Value\n",
    "\n",
    "- Tend to get sparse vectors (small weights go to 0)\n",
    "- Reduce number of weights\n",
    "- Good feature selection to pick out importance\n",
    "\n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\dfrac{\\lambda}{m}|w_i| \\big]$$\n",
    "\n",
    "\n",
    "## L2 Regularization - Squared Value\n",
    "\n",
    "- Not sparse vectors (weights homogeneous & small)\n",
    "- Gives better results for training\n",
    "    + subtle; consider vectors: [1,0] & [0.5, 0.5] \n",
    "    + recall we want smallest value for our value\n",
    "    + L2 prefers [0.5,0.5] over [1,0] \n",
    "    \n",
    "$$ J(W,b) = -\\dfrac{1}{m} \\sum^m_{i=1}\\big[\\mathcal{L}(\\hat y_i, y_i)+ \\dfrac{\\lambda}{m}w_i^2 \\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You want to even out your workouts, otherwise you may have some strange results..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='images/homer-dropout-comparison.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well, our neural network models are the same way. The model should get _evenly_ trained. We don't want to train the same node/pathway over and over again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Avoiding the Self-Perpetuating Strength Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When working out, we'd train our left and right arms evenly and switch our exercise routine throughout the week.\n",
    "\n",
    "In neural networks, we switch around which nodes we use during our training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Assign a probability of using a given node for that epoch (usually about 20% chance). When we have many epochs, we likely will even out the randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='images/layered-neural-net.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T06:00:55.498491Z",
     "start_time": "2019-06-19T06:00:55.420689Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(128, input_dim=100, activation='relu', name='input_layer'))\n",
    "model.add(Dropout(0.2, name='input_dropout'))\n",
    "# Hidden Layer\n",
    "model.add(Dense(256, input_dim=100, activation='relu', name='hidden_layer1'))\n",
    "model.add(Dropout(0.2, name='hidden_layer1_dropout'))\n",
    "# Output Layer\n",
    "model.add(Dense(n_classes, activation='softmax', name='output'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
