{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Making-the-Split---Information-Gain\" data-toc-modified-id=\"Making-the-Split---Information-Gain-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Making the Split - Information Gain</a></span><ul class=\"toc-item\"><li><span><a href=\"#Entropy\" data-toc-modified-id=\"Entropy-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Entropy</a></span></li><li><span><a href=\"#Information\" data-toc-modified-id=\"Information-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Information</a></span></li><li><span><a href=\"#Shannon's-Entropy\" data-toc-modified-id=\"Shannon's-Entropy-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Shannon's Entropy</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-Situation\" data-toc-modified-id=\"A-Situation-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>A Situation</a></span></li><li><span><a href=\"#Let's-Quantify-This\" data-toc-modified-id=\"Let's-Quantify-This-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Let's Quantify This</a></span></li></ul></li><li><span><a href=\"#Using-Information-to-Split\" data-toc-modified-id=\"Using-Information-to-Split-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Using Information to Split</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quantifying-information-gain\" data-toc-modified-id=\"Quantifying-information-gain-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Quantifying information gain</a></span></li></ul></li></ul></li><li><span><a href=\"#Hyperparameters\" data-toc-modified-id=\"Hyperparameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Max-Depth\" data-toc-modified-id=\"Max-Depth-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Max Depth</a></span></li><li><span><a href=\"#Minimum-Number-of-Samples-per-Leaf\" data-toc-modified-id=\"Minimum-Number-of-Samples-per-Leaf-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Minimum Number of Samples per Leaf</a></span></li><li><span><a href=\"#Minimum-Number-of-Samples-per-Split\" data-toc-modified-id=\"Minimum-Number-of-Samples-per-Split-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Minimum Number of Samples per Split</a></span></li><li><span><a href=\"#Maximum-Number-of-Features\" data-toc-modified-id=\"Maximum-Number-of-Features-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Maximum Number of Features</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Split - Information Gain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is funny, it basically describes the ways you can rearrange junk\n",
    "\n",
    "Sometimes referenced as \"disorder\" since more disorder gives many options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many possibilities do we have to arrange 5 identical blue balls?\n",
    "- How many possibilities do we have to arrange 4 identical blue balls and 1 red ball?\n",
    "- How many possibilities do we have to arrange 3 identical blue balls and 2 red balls?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to pick a ball at random for each situation above, could we know what ball color it likely is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that higher entropy has, the more information we have about what ball we likely will pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shannon's Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 identical blue balls\n",
    "- 4 identical blue balls and 1 red ball\n",
    "- 3 identical blue balls and 2 red balls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to the ball situations and we play a game:\n",
    "- Draw a ball one a time (putting it back after drawing) for a total of 4 times\n",
    "- If we get a total of 3 blue balls, we win!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability of winning in each situation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Quantify This"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, probabilities are fine, but we hate to multiply (harder to deal with)\n",
    "So we do the log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quantify this information by **Shannon's form of entropy**:\n",
    "\n",
    "$$ H(S) = -\\sum_i^n {p_i log(p_i)} $$\n",
    "\n",
    "> Note usually would be using $log$ in base 2 but really it doesn't matter in quantifying the entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Information to Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/learn-co-students/dsc-3-31-04-entropy-information-gain-online-ds-sp-000/master/images/split.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ IG(A, S) = H(S) - \\sum_{t\\in A}P(t) H(t) $$\n",
    "\n",
    "where $A$ is some attribute and $t$ is some subset of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write this similarly for a two split decision tree:\n",
    "\n",
    "IG = Entropy(Parent) - ($\\frac{m}{m+n}$ Entropy(1st child) + $\\frac{n}{m+n}$ Entropy(2nd child) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We can also split on continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful to consider to make sure you don't overfit or underfit\n",
    "\n",
    "Check out the scikit-learn documentation: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_depth`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Number of Samples per Leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min_samples_leaf`\n",
    "\n",
    "The smallest number of samples that can be in a leaf (node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Number of Samples per Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min_samples_split`\n",
    "\n",
    "The smallest number of samples in a leaf (node) before splitting it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Number of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_features`\n",
    "\n",
    "Most features to consider when splitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
